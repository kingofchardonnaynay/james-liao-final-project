{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import streamlit as st\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import psycopg2\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import easyocr\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection\n",
    "\n",
    "# Function to create a PostgreSQL connection as the readonly user for querying\n",
    "def get_read_only_connection():\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        database=\"pokemontcg\",  # Replace with your database name\n",
    "        user=\"readonly_user\",  # Shared read-only user\n",
    "        password=\"D8G*pBDz*koJ\"  # Password for the shared user\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "# Function to connect as the logging user for logging, retrieving credentials from environment variables\n",
    "def get_logging_connection():\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        database=\"pokemontcg\",  # Replace with your database name\n",
    "        user=os.getenv(\"PG_LOGGING_USER\"),  # Logging user from environment variable\n",
    "        password=os.getenv(\"PG_LOGGING_PASSWORD\")  # Logging password from environment variable\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "# Function to log the user's activity into the restricted_logs.user_logs table\n",
    "def log_user_activity(username):\n",
    "    conn = get_logging_connection()  # Use the logging user connection to insert logs\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Insert the user's name and login time into the user_logs table\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO restricted_logs.user_logs (username, login_time)\n",
    "    VALUES (%s, CURRENT_TIMESTAMP);\n",
    "    \"\"\"\n",
    "    cursor.execute(insert_query, (username,))\n",
    "    \n",
    "    # Commit the transaction and close the connection\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trained Set-Symbol Model loading\n",
    "model = load_model(r\"C:\\Users\\Jimmy\\Desktop\\final-project\\PokemonTCG\\models\\model04.keras\")  # Load your pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easyReader OCR initialization\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounding box, ROI and OCR logic\n",
    "# Function to classify a card as white or non-white\n",
    "def classify_card(image_rgb):\n",
    "    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    mean_brightness = np.mean(gray)\n",
    "    \n",
    "    if mean_brightness > 150:\n",
    "        return \"white\"\n",
    "    else:\n",
    "        return \"non_white\"\n",
    "\n",
    "\n",
    "# Function to adjust brightness and contrast\n",
    "def adjust_brightness_contrast(image, alpha=2, beta=25):\n",
    "    return cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "\n",
    "# Function to display images for debugging\n",
    "def debug_show_image(image, title=\"Image\"):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Preprocessing to identify all colors that are not black and turn them into white\n",
    "def ocr_preprocessing1(image_roi):\n",
    "    roi_gray = cv2.cvtColor(image_roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, roi_thresh_black = cv2.threshold(roi_gray, 30, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    roi_contrast = adjust_brightness_contrast(roi_thresh_black, alpha=1.5, beta=30)\n",
    "    roi_blur = cv2.GaussianBlur(roi_contrast, (3, 3), 0)\n",
    "    roi_thresh = cv2.adaptiveThreshold(roi_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    roi_sharpen = cv2.filter2D(roi_thresh, -1, np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]]))\n",
    "    \n",
    "    debug_show_image(roi_sharpen, title=\"Preprocessed\")\n",
    "    return roi_sharpen\n",
    "\n",
    "\n",
    "# OCR processing with EasyOCR\n",
    "def perform_ocr_easyocr(image_roi):\n",
    "    # Perform OCR using EasyOCR\n",
    "    result = reader.readtext(image_roi, detail=0)\n",
    "    print(f\"OCR result: {result}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Function to process OCR results and select only the valid match\n",
    "def process_ocr_results(ocr_results):\n",
    "    # Define the patterns for the two cases\n",
    "    pattern_letters_digits = r'[a-zA-Z]{2,4}\\d{1,3}'  # 2-4 letters followed by 1-3 numbers\n",
    "    pattern_numbers_slash = r'\\d{1,3}/\\d{2,3}'  # 1-3 numbers followed by / and 2-3 numbers\n",
    "\n",
    "    for result in ocr_results:\n",
    "        # Try to match both patterns\n",
    "        match_letters_digits = re.search(pattern_letters_digits, result)\n",
    "        match_numbers_slash = re.search(pattern_numbers_slash, result)\n",
    "\n",
    "        # Return only the matched portion, if found\n",
    "        if match_letters_digits:\n",
    "            return match_letters_digits.group()  # Return the first valid match for letters-digits\n",
    "        elif match_numbers_slash:\n",
    "            return match_numbers_slash.group()  # Return the first valid match for numbers-slash\n",
    "\n",
    "    return None  # Return None if no valid match is found\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract bounding boxes and run OCR on white cards\n",
    "def draw_bounding_box_white(image_bgr):\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # --- First Text ROI (for OCR) ---\n",
    "        text_roi_height = h // 10\n",
    "        text_roi_width = int(w * 0.5)\n",
    "        text_roi_y_start = y + h - text_roi_height\n",
    "        first_text_roi = image_bgr[text_roi_y_start:text_roi_y_start + text_roi_height, x:x + text_roi_width]\n",
    "\n",
    "        # Debugging: show the first ROI before preprocessing\n",
    "        debug_show_image(first_text_roi, title=\"First Text ROI Before Preprocessing\")\n",
    "\n",
    "        processed_first_text_roi = ocr_preprocessing1(first_text_roi)\n",
    "        ocr_results_first = perform_ocr_easyocr(processed_first_text_roi)\n",
    "\n",
    "        # --- Second Text ROI ---\n",
    "        second_text_roi_height = int(text_roi_height * 1.2)\n",
    "        second_text_roi_x_start = x + w - text_roi_width\n",
    "        second_text_roi_y_start = y + h - second_text_roi_height\n",
    "        second_text_roi = image_bgr[second_text_roi_y_start:second_text_roi_y_start + second_text_roi_height,\n",
    "                                    second_text_roi_x_start:second_text_roi_x_start + text_roi_width]\n",
    "\n",
    "        # Debugging: show the second ROI before preprocessing\n",
    "        debug_show_image(second_text_roi, title=\"Second Text ROI Before Preprocessing\")\n",
    "\n",
    "        processed_second_text_roi = ocr_preprocessing1(second_text_roi)\n",
    "        ocr_results_second = perform_ocr_easyocr(processed_second_text_roi)\n",
    "\n",
    "        # --- Decision: Keep only one OCR result ---\n",
    "        processed_ocr_result_first = process_ocr_results(ocr_results_first)\n",
    "        processed_ocr_result_second = process_ocr_results(ocr_results_second)\n",
    "\n",
    "        final_ocr_result = processed_ocr_result_first if processed_ocr_result_first else processed_ocr_result_second\n",
    "\n",
    "        # --- Set Symbol ROIs ---\n",
    "        roi_bottom_left = (x, y + h - text_roi_height, w // 4, text_roi_height)\n",
    "        roi_bottom_right = (x + w // 2 + w // 4, y + h - 2 * text_roi_height + int(0.15 * text_roi_height), w // 4, text_roi_height)\n",
    "        roi_middle = (x + w // 2 + w // 4, y + h // 2, w // 4, text_roi_height)\n",
    "\n",
    "        # Draw bounding box and ROIs\n",
    "        image_with_rois = image_bgr.copy()\n",
    "        cv2.rectangle(image_with_rois, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Draw the first text ROI (blue)\n",
    "        cv2.rectangle(image_with_rois, (x, text_roi_y_start), (x + text_roi_width, text_roi_y_start + text_roi_height), (255, 0, 0), 2)\n",
    "        \n",
    "        # Draw the second text ROI (red)\n",
    "        cv2.rectangle(image_with_rois, (second_text_roi_x_start, second_text_roi_y_start), \n",
    "                      (second_text_roi_x_start + text_roi_width, second_text_roi_y_start + second_text_roi_height), (255, 0, 0), 2)\n",
    "\n",
    "        # Draw the three set symbol ROIs (yellow)\n",
    "        cv2.rectangle(image_with_rois, (roi_bottom_left[0], roi_bottom_left[1]),\n",
    "                      (roi_bottom_left[0] + roi_bottom_left[2], roi_bottom_left[1] + roi_bottom_left[3]),\n",
    "                      (255, 255, 0), 2)  # Yellow for set symbol ROI\n",
    "\n",
    "        cv2.rectangle(image_with_rois, (roi_bottom_right[0], roi_bottom_right[1]),\n",
    "                      (roi_bottom_right[0] + roi_bottom_right[2], roi_bottom_right[1] + roi_bottom_right[3]),\n",
    "                      (255, 255, 0), 2)  # Yellow for set symbol ROI\n",
    "\n",
    "        cv2.rectangle(image_with_rois, (roi_middle[0], roi_middle[1]),\n",
    "                      (roi_middle[0] + roi_middle[2], roi_middle[1] + roi_middle[3]),\n",
    "                      (255, 255, 0), 2)  # Yellow for set symbol ROI\n",
    "        return image_with_rois, final_ocr_result\n",
    "\n",
    "    else:\n",
    "        print(\"No contours found.\")\n",
    "        return image_bgr, None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract bounding boxes and run OCR on non-white cards\n",
    "def draw_bounding_boxes(image_rgb, threshold_value):\n",
    "    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    _, thresholded = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "\n",
    "        # --- First Text ROI ---\n",
    "        text_roi_height = h // 10\n",
    "        text_roi_width = int(w * 0.5)\n",
    "        text_roi_y_start = y + h - text_roi_height\n",
    "        first_text_roi = image_rgb[text_roi_y_start:text_roi_y_start + text_roi_height, x:x + text_roi_width]\n",
    "\n",
    "        # Debugging: show the first ROI before preprocessing\n",
    "        debug_show_image(first_text_roi, title=\"First Text ROI Before Preprocessing (Non-White)\")\n",
    "\n",
    "        processed_first_text_roi = ocr_preprocessing1(first_text_roi)\n",
    "        ocr_results_first = perform_ocr_easyocr(processed_first_text_roi)\n",
    "\n",
    "        # --- Second Text ROI ---\n",
    "        second_text_roi_height = int(text_roi_height * 1.2)\n",
    "        second_text_roi_x_start = x + w - text_roi_width\n",
    "        second_text_roi_y_start = y + h - second_text_roi_height\n",
    "        second_text_roi = image_rgb[second_text_roi_y_start:second_text_roi_y_start + second_text_roi_height,\n",
    "                                    second_text_roi_x_start:second_text_roi_x_start + text_roi_width]\n",
    "\n",
    "        # Debugging: show the second ROI before preprocessing\n",
    "        debug_show_image(second_text_roi, title=\"Second Text ROI Before Preprocessing (Non-White)\")\n",
    "\n",
    "        processed_second_text_roi = ocr_preprocessing1(second_text_roi)\n",
    "        ocr_results_second = perform_ocr_easyocr(processed_second_text_roi)\n",
    "\n",
    "        # --- Decision: Keep only one OCR result ---\n",
    "        processed_ocr_result_first = process_ocr_results(ocr_results_first)\n",
    "        processed_ocr_result_second = process_ocr_results(ocr_results_second)\n",
    "\n",
    "        final_ocr_result = processed_ocr_result_first if processed_ocr_result_first else processed_ocr_result_second\n",
    "\n",
    "        # --- Set Symbol ROIs ---\n",
    "        roi_bottom_left = (x, y + h - text_roi_height, w // 4, text_roi_height)\n",
    "        \n",
    "        # Directly calculating roi_bottom_right without intermediate y calculation\n",
    "        roi_bottom_right = (x + w // 2 + w // 4, y + h - 2 * text_roi_height + int(0.15 * text_roi_height), w // 4, text_roi_height)\n",
    "        \n",
    "        roi_middle = (x + w // 2 + w // 4, y + h // 2, w // 4, text_roi_height)\n",
    "\n",
    "        # Draw bounding box and ROIs\n",
    "        image_with_rois = image_rgb.copy()\n",
    "        cv2.rectangle(image_with_rois, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Draw the first text ROI (blue)\n",
    "        cv2.rectangle(image_with_rois, (x, text_roi_y_start), (x + text_roi_width, text_roi_y_start + text_roi_height), (255, 0, 0), 2)\n",
    "        \n",
    "        # Draw the second text ROI (red)\n",
    "        cv2.rectangle(image_with_rois, (second_text_roi_x_start, second_text_roi_y_start), \n",
    "                      (second_text_roi_x_start + text_roi_width, second_text_roi_y_start + second_text_roi_height), (255, 0, 0), 2)\n",
    "\n",
    "        # Draw the three set symbol ROIs (yellow)\n",
    "        cv2.rectangle(image_with_rois, (roi_bottom_left[0], roi_bottom_left[1]),\n",
    "                      (roi_bottom_left[0] + roi_bottom_left[2], roi_bottom_left[1] + roi_bottom_left[3]),\n",
    "                      (255, 255, 0), 2)  # Yellow for set symbol ROI\n",
    "\n",
    "        cv2.rectangle(image_with_rois, (roi_bottom_right[0], roi_bottom_right[1]),\n",
    "                      (roi_bottom_right[0] + roi_bottom_right[2], roi_bottom_right[1] + roi_bottom_right[3]),\n",
    "                      (255, 255, 0), 2)  # Yellow for set symbol ROI\n",
    "\n",
    "        cv2.rectangle(image_with_rois, (roi_middle[0], roi_middle[1]),\n",
    "                      (roi_middle[0] + roi_middle[2], roi_middle[1] + roi_middle[3]),\n",
    "                      (255, 255, 0), 2)  # Yellow for set symbol ROI\n",
    "        \n",
    "        return image_with_rois, final_ocr_result\n",
    "    else:\n",
    "        print(\"No contours found.\")\n",
    "        return image_rgb, None, None\n",
    "\n",
    "\n",
    "\n",
    "# Main function to handle both white and non-white cards\n",
    "def bounding_box_roi(image_rgb):\n",
    "    card_type = classify_card(image_rgb)\n",
    "\n",
    "    if card_type == \"white\":\n",
    "        image_with_bounding_box, ocr_result= draw_bounding_box_white(image_rgb)\n",
    "    else:\n",
    "        threshold_value = 160\n",
    "        image_with_bounding_box, ocr_result= draw_bounding_boxes(image_rgb, threshold_value)\n",
    "\n",
    "    return image_with_bounding_box, ocr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamlit setup\n",
    "\n",
    "# Set the title for the home page\n",
    "st.title(\"Welcome to My Pokemon Card Identifier App\")\n",
    "\n",
    "# Display some text (description)\n",
    "st.write(\"This is the home page of my app. Here you can upload an image and view it below. The image uploaded should be a single Pokemon card on a white background. The entire card should be in frame.\")\n",
    "\n",
    "# Input for name\n",
    "name = st.text_input(\"Enter your name to log in:\")\n",
    "\n",
    "if name and not st.session_state.get('name'):\n",
    "    st.session_state['name'] = name\n",
    "    log_user_activity(name)  # Log the user's name and login time in the restricted schema\n",
    "    st.success(f\"Welcome, {name}! You are now logged in.\")\n",
    "\n",
    "# Only allow access to the rest of the app if the user has entered their name\n",
    "if st.session_state.get('name'):\n",
    "    # File uploader for image input\n",
    "    uploaded_image = st.file_uploader(\"Upload an image of the card\", type=[\"jpg\", \"jpeg\", \"png\", \"webp\"])\n",
    "\n",
    "    if uploaded_image is not None:\n",
    "        # Open and display the uploaded image\n",
    "        image = Image.open(uploaded_image)\n",
    "        st.image(image, caption=\"Uploaded image\", use_column_width=True)\n",
    "        \n",
    "        # Convert the image to RGB\n",
    "        image_rgb = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Use the provided function to process the image\n",
    "        image_with_bounding_box, ocr_result = bounding_box_roi(image_rgb)\n",
    "\n",
    "        # Display the processed image with bounding boxes\n",
    "        st.image(image_with_bounding_box, caption=\"Processed Image with Bounding Boxes\", use_column_width=True)\n",
    "        \n",
    "        # Display the OCR result\n",
    "        st.write(f\"OCR Result: {ocr_result}\")\n",
    "\n",
    "        # Placeholder: Process the symbol ROI using the pre-trained model\n",
    "        \n",
    "        # Assuming symbol ROIs are extracted in your function, and you pass them through the model:\n",
    "        symbol_roi = extract_symbol_roi(image_rgb)  # Placeholder: Replace this with actual symbol ROI extraction\n",
    "\n",
    "        # Preprocess the symbol ROI before passing it into the model\n",
    "        symbol_roi_preprocessed = preprocess_symbol_roi(symbol_roi)  # Example: Resize, normalize, etc.\n",
    "    \n",
    "\n",
    "        # Predict the symbol using the model\n",
    "        symbol_prediction = model.predict(symbol_roi_preprocessed)\n",
    "\n",
    "        # Interpret the prediction\n",
    "        predicted_symbol_class = interpret_symbol_prediction(symbol_prediction)  # Example: map prediction to class\n",
    "\n",
    "        st.write(f\"Predicted Symbol Class: {predicted_symbol_class}\")\n",
    "\n",
    "else:\n",
    "    st.warning(\"Please enter your name to continue.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
